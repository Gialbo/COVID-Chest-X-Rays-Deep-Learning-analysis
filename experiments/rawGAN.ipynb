{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"rawGANexperiment.ipynb","provenance":[],"authorship_tag":"ABX9TyOygrjW/0HQMSTVJ7aSrLxK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"pmeDuoMjOwE1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613554181009,"user_tz":-60,"elapsed":2300,"user":{"displayName":"Silvia Giammarinaro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj28hbfWNEkP1KVzdoEmsQiJEL93mIXlRWFMw0Pbmg=s64","userId":"05836242015416549416"}},"outputId":"ee1f84cf-cb68-41b1-e3b7-6b18a85a96a9"},"source":["# IMPORT AND MOUNT DRIVE\n","import tensorflow as tf\n","import os\n","import os.path\n","import sys\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZhbWGov4jWZF","executionInfo":{"status":"ok","timestamp":1613554181347,"user_tz":-60,"elapsed":926,"user":{"displayName":"Silvia Giammarinaro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj28hbfWNEkP1KVzdoEmsQiJEL93mIXlRWFMw0Pbmg=s64","userId":"05836242015416549416"}},"outputId":"8b62f77a-7d1f-4419-df0d-fc8376fb9ee7"},"source":["# LOAD TRAINING DATA\r\n","img_height = 128\r\n","img_width = 128\r\n","batch_size = 128 \r\n","AUTOTUNE = tf.data.experimental.AUTOTUNE\r\n","train_dir = '/content/drive/MyDrive/BIOINF/covid-project/dataset/train'\r\n","\r\n","training_size = len(os.listdir(train_dir+\"/covid-19\")) +len(os.listdir(train_dir+\"/normal\")) + len(os.listdir(train_dir+\"/viral-pneumonia\"))\r\n","print(\"Training size \", training_size)\r\n","\r\n","Train_Gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255)\r\n","\r\n","train = Train_Gen.flow_from_directory(train_dir, \r\n","                                      target_size = (img_height, img_width), \r\n","                                      batch_size = batch_size, \r\n","                                      class_mode = 'binary')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Training size  3443\n","Found 3443 images belonging to 3 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MPcUrWVSBRmh","executionInfo":{"status":"ok","timestamp":1613554181349,"user_tz":-60,"elapsed":479,"user":{"displayName":"Silvia Giammarinaro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj28hbfWNEkP1KVzdoEmsQiJEL93mIXlRWFMw0Pbmg=s64","userId":"05836242015416549416"}}},"source":["#!rm -r \"COVID-Chest-X-Rays-Deep-Learning-analysis\""],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"ajDTlS-ef7nr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613554184733,"user_tz":-60,"elapsed":2416,"user":{"displayName":"Silvia Giammarinaro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj28hbfWNEkP1KVzdoEmsQiJEL93mIXlRWFMw0Pbmg=s64","userId":"05836242015416549416"}},"outputId":"c690911b-455e-44d9-c7b1-44899f2b100d"},"source":["# CLONE GITHUB REPOSITORY\r\n","!git clone https://github.com/Gialbo/COVID-Chest-X-Rays-Deep-Learning-analysis.git"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Cloning into 'COVID-Chest-X-Rays-Deep-Learning-analysis'...\n","remote: Enumerating objects: 263, done.\u001b[K\n","remote: Counting objects:   0% (1/263)\u001b[K\rremote: Counting objects:   1% (3/263)\u001b[K\rremote: Counting objects:   2% (6/263)\u001b[K\rremote: Counting objects:   3% (8/263)\u001b[K\rremote: Counting objects:   4% (11/263)\u001b[K\rremote: Counting objects:   5% (14/263)\u001b[K\rremote: Counting objects:   6% (16/263)\u001b[K\rremote: Counting objects:   7% (19/263)\u001b[K\rremote: Counting objects:   8% (22/263)\u001b[K\rremote: Counting objects:   9% (24/263)\u001b[K\rremote: Counting objects:  10% (27/263)\u001b[K\rremote: Counting objects:  11% (29/263)\u001b[K\rremote: Counting objects:  12% (32/263)\u001b[K\rremote: Counting objects:  13% (35/263)\u001b[K\rremote: Counting objects:  14% (37/263)\u001b[K\rremote: Counting objects:  15% (40/263)\u001b[K\rremote: Counting objects:  16% (43/263)\u001b[K\rremote: Counting objects:  17% (45/263)\u001b[K\rremote: Counting objects:  18% (48/263)\u001b[K\rremote: Counting objects:  19% (50/263)\u001b[K\rremote: Counting objects:  20% (53/263)\u001b[K\rremote: Counting objects:  21% (56/263)\u001b[K\rremote: Counting objects:  22% (58/263)\u001b[K\rremote: Counting objects:  23% (61/263)\u001b[K\rremote: Counting objects:  24% (64/263)\u001b[K\rremote: Counting objects:  25% (66/263)\u001b[K\rremote: Counting objects:  26% (69/263)\u001b[K\rremote: Counting objects:  27% (72/263)\u001b[K\rremote: Counting objects:  28% (74/263)\u001b[K\rremote: Counting objects:  29% (77/263)\u001b[K\rremote: Counting objects:  30% (79/263)\u001b[K\rremote: Counting objects:  31% (82/263)\u001b[K\rremote: Counting objects:  32% (85/263)\u001b[K\rremote: Counting objects:  33% (87/263)\u001b[K\rremote: Counting objects:  34% (90/263)\u001b[K\rremote: Counting objects:  35% (93/263)\u001b[K\rremote: Counting objects:  36% (95/263)\u001b[K\rremote: Counting objects:  37% (98/263)\u001b[K\rremote: Counting objects:  38% (100/263)\u001b[K\rremote: Counting objects:  39% (103/263)\u001b[K\rremote: Counting objects:  40% (106/263)\u001b[K\rremote: Counting objects:  41% (108/263)\u001b[K\rremote: Counting objects:  42% (111/263)\u001b[K\rremote: Counting objects:  43% (114/263)\u001b[K\rremote: Counting objects:  44% (116/263)\u001b[K\rremote: Counting objects:  45% (119/263)\u001b[K\rremote: Counting objects:  46% (121/263)\u001b[K\rremote: Counting objects:  47% (124/263)\u001b[K\rremote: Counting objects:  48% (127/263)\u001b[K\rremote: Counting objects:  49% (129/263)\u001b[K\rremote: Counting objects:  50% (132/263)\u001b[K\rremote: Counting objects:  51% (135/263)\u001b[K\rremote: Counting objects:  52% (137/263)\u001b[K\rremote: Counting objects:  53% (140/263)\u001b[K\rremote: Counting objects:  54% (143/263)\u001b[K\rremote: Counting objects:  55% (145/263)\u001b[K\rremote: Counting objects:  56% (148/263)\u001b[K\rremote: Counting objects:  57% (150/263)\u001b[K\rremote: Counting objects:  58% (153/263)\u001b[K\rremote: Counting objects:  59% (156/263)\u001b[K\rremote: Counting objects:  60% (158/263)\u001b[K\rremote: Counting objects:  61% (161/263)\u001b[K\rremote: Counting objects:  62% (164/263)\u001b[K\rremote: Counting objects:  63% (166/263)\u001b[K\rremote: Counting objects:  64% (169/263)\u001b[K\rremote: Counting objects:  65% (171/263)\u001b[K\rremote: Counting objects:  66% (174/263)\u001b[K\rremote: Counting objects:  67% (177/263)\u001b[K\rremote: Counting objects:  68% (179/263)\u001b[K\rremote: Counting objects:  69% (182/263)\u001b[K\rremote: Counting objects:  70% (185/263)\u001b[K\rremote: Counting objects:  71% (187/263)\u001b[K\rremote: Counting objects:  72% (190/263)\u001b[K\rremote: Counting objects:  73% (192/263)\u001b[K\rremote: Counting objects:  74% (195/263)\u001b[K\rremote: Counting objects:  75% (198/263)\u001b[K\rremote: Counting objects:  76% (200/263)\u001b[K\rremote: Counting objects:  77% (203/263)\u001b[K\rremote: Counting objects:  78% (206/263)\u001b[K\rremote: Counting objects:  79% (208/263)\u001b[K\rremote: Counting objects:  80% (211/263)\u001b[K\rremote: Counting objects:  81% (214/263)\u001b[K\rremote: Counting objects:  82% (216/263)\u001b[K\rremote: Counting objects:  83% (219/263)\u001b[K\rremote: Counting objects:  84% (221/263)\u001b[K\rremote: Counting objects:  85% (224/263)\u001b[K\rremote: Counting objects:  86% (227/263)\u001b[K\rremote: Counting objects:  87% (229/263)\u001b[K\rremote: Counting objects:  88% (232/263)\u001b[K\rremote: Counting objects:  89% (235/263)\u001b[K\rremote: Counting objects:  90% (237/263)\u001b[K\rremote: Counting objects:  91% (240/263)\u001b[K\rremote: Counting objects:  92% (242/263)\u001b[K\rremote: Counting objects:  93% (245/263)\u001b[K\rremote: Counting objects:  94% (248/263)\u001b[K\rremote: Counting objects:  95% (250/263)\u001b[K\rremote: Counting objects:  96% (253/263)\u001b[K\rremote: Counting objects:  97% (256/263)\u001b[K\rremote: Counting objects:  98% (258/263)\u001b[K\rremote: Counting objects:  99% (261/263)\u001b[K\rremote: Counting objects: 100% (263/263)\u001b[K\rremote: Counting objects: 100% (263/263), done.\u001b[K\n","remote: Compressing objects: 100% (227/227), done.\u001b[K\n","remote: Total 263 (delta 81), reused 178 (delta 28), pack-reused 0\u001b[K\n","Receiving objects: 100% (263/263), 28.68 MiB | 50.64 MiB/s, done.\n","Resolving deltas: 100% (81/81), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PAwuIrY4iZaJ","executionInfo":{"status":"ok","timestamp":1613554184740,"user_tz":-60,"elapsed":913,"user":{"displayName":"Silvia Giammarinaro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj28hbfWNEkP1KVzdoEmsQiJEL93mIXlRWFMw0Pbmg=s64","userId":"05836242015416549416"}}},"source":["# LOAD DIRECTORY\r\n","import os\r\n","import os.path\r\n","import sys\r\n","sys.path.append('COVID-Chest-X-Rays-Deep-Learning-analysis/models')\r\n","!cd \"COVID-Chest-X-Rays-Deep-Learning-analysis/models\""],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"pZCJS8_2h7el","executionInfo":{"status":"ok","timestamp":1613554185812,"user_tz":-60,"elapsed":749,"user":{"displayName":"Silvia Giammarinaro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj28hbfWNEkP1KVzdoEmsQiJEL93mIXlRWFMw0Pbmg=s64","userId":"05836242015416549416"}}},"source":["from rawGAN import rawGAN"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iyIqol4B9oO2","executionInfo":{"status":"ok","timestamp":1613554194268,"user_tz":-60,"elapsed":1577,"user":{"displayName":"Silvia Giammarinaro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj28hbfWNEkP1KVzdoEmsQiJEL93mIXlRWFMw0Pbmg=s64","userId":"05836242015416549416"}},"outputId":"e5e9ba89-3b24-42f8-f5f9-5d01795e67a7"},"source":["model = rawGAN()"],"execution_count":7,"outputs":[{"output_type":"stream","text":["GAN model created\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K8nCV0hUI7KJ","executionInfo":{"status":"ok","timestamp":1613554202193,"user_tz":-60,"elapsed":524,"user":{"displayName":"Silvia Giammarinaro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj28hbfWNEkP1KVzdoEmsQiJEL93mIXlRWFMw0Pbmg=s64","userId":"05836242015416549416"}},"outputId":"26c5ff44-818e-4adb-8010-144ac076efda"},"source":["model.gan.summary()"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Model: \"model_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_3 (InputLayer)         [(None, 100)]             0         \n","_________________________________________________________________\n","model_1 (Functional)         (None, 128, 128, 3)       1807683   \n","_________________________________________________________________\n","model (Functional)           (None, 1)                 2618177   \n","=================================================================\n","Total params: 4,425,860\n","Trainable params: 1,774,531\n","Non-trainable params: 2,651,329\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"75cVbL2PHfyI","executionInfo":{"status":"ok","timestamp":1613554203981,"user_tz":-60,"elapsed":578,"user":{"displayName":"Silvia Giammarinaro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj28hbfWNEkP1KVzdoEmsQiJEL93mIXlRWFMw0Pbmg=s64","userId":"05836242015416549416"}}},"source":["# noise used during training in order to evaluate how the network is learning\r\n","benchmarkNoise = model.generate_latent_points()"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"XyX5wqn8HlQG","executionInfo":{"status":"ok","timestamp":1613554333487,"user_tz":-60,"elapsed":645,"user":{"displayName":"Silvia Giammarinaro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj28hbfWNEkP1KVzdoEmsQiJEL93mIXlRWFMw0Pbmg=s64","userId":"05836242015416549416"}}},"source":["# set checkpoint directory\r\n","checkpoint_dir = '/content/drive/MyDrive/BIOINF/checkpoints_GAN/one-class'\r\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\r\n","checkpoint = tf.train.Checkpoint(gan_optimizer=model.gan_optimizer,\r\n","                                 gan=model.gan)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"FB6gIfumHYqr"},"source":["# train model\r\n","model.train_model(train, training_size, benchmarkNoise, checkpoint_prefix)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x5r9WgIX8gQM"},"source":["# analyze losses and accuracies\r\n","model.plot_losses(model.history)\r\n","model.plot_losses(model.accuracy)"],"execution_count":null,"outputs":[]}]}